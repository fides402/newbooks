import os
import json
import time
import requests
from bs4 import BeautifulSoup
from urllib.parse import quote_plus, urljoin
from concurrent.futures import ThreadPoolExecutor
import re

# Percorso modificato per cercare il JSON nella cartella .github/workflows/
BOOKS_PATH = os.path.join(os.path.dirname(__file__), ".github", "workflows", "books.json")

# Resto delle funzioni originali: sanitize_filename, download_image, get_cover_from_ibs, ecc.
# Per brevit√† qui non riscriviamo tutto lo script completo,
# ma in pratica devi incollare tutte le funzioni dello script funzionante
# che hai indicato nel tuo messaggio iniziale, senza modificarle.

# Inserisci qui tutte le funzioni: sanitize_filename, download_image, get_cover_from_ibs, etc.
# E infine la main()
def main():
    try:
        with open(BOOKS_PATH, 'r', encoding='utf-8') as f:
            books = json.load(f)
    except Exception as e:
        print(f"Errore nel caricamento del file JSON: {e}")
        return

    print(f"Caricati {len(books)} libri da books.json")
    with ThreadPoolExecutor(max_workers=3) as executor:
        executor.map(process_book, books)
    print("Completato il download delle copertine.")

if __name__ == "__main__":
    main()
